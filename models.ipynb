{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives  (1600, 37) (8397, 37)\n",
      "negatives  (1679, 37)\n",
      "(3279, 37) (3279, 36) (3279,)\n"
     ]
    }
   ],
   "source": [
    "X=pd.read_csv(\"X.csv\",header=None)\n",
    "Y=pd.read_csv(\"Y.csv\",header=None)\n",
    "\n",
    "x =np.asarray(X)\n",
    "Y_arr = np.asarray(Y)\n",
    "\n",
    "# normalize\n",
    "x_normed = (x - x.mean(axis=0))/x.std(axis=0)\n",
    "x_normed=(x_normed)\n",
    "\n",
    "# Under sample it\n",
    "\n",
    "# combine x and y\n",
    "xy=np.concatenate((x_normed,Y_arr),axis=1)\n",
    "df=pd.DataFrame(xy) # the last column is label\n",
    "\n",
    "# seperate y=0 and y=1 rows\n",
    "negatives=df[df[df.columns[36]]==0.0]\n",
    "positives=df[df[df.columns[36]]==1.0]\n",
    "print \"positives \",positives.shape,negatives.shape\n",
    "random_negatives=negatives.sample(frac=0.2,random_state=11L)\n",
    "print \"negatives \",random_negatives.shape\n",
    "sampled=np.concatenate((np.asarray(positives),np.asarray(random_negatives)),axis=0)\n",
    "x_normed=sampled[:,0:36]\n",
    "Y_arr=sampled[:,36]\n",
    "print sampled.shape,x_normed.shape,Y_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.pcolor(np.abs(np.corrcoef(x_normed.T)))\n",
    "plt.colorbar()\n",
    "plt.xlim(0, 36)\n",
    "plt.ylim(0,36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find most relevant features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n"
     ]
    }
   ],
   "source": [
    "# from http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#example-ensemble-plot-forest-importances-py\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "forest = ExtraTreesClassifier(n_estimators=250,random_state=0)\n",
    "forest.fit(x_normed, Y_arr)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#for f in range(x_normed.shape[1]):\n",
    "#    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x_normed.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(x_normed.shape[1]), indices)\n",
    "plt.xlim([-1, x_normed.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduce features\n",
    "x_normed=np.delete(x_normed,[14,15],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression and decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3279, 34)\n",
      "[0.63910802342008721, 0.64211392848481585, 0.65163449478404611] [0.042939514681446009, 0.029643126857972518, 0.034883694076084472]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "print x_normed.shape\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_normed, Y_arr, test_size=0.3)\n",
    "k_fold = StratifiedKFold(y_train.ravel(), n_folds=10)\n",
    "\n",
    "auc=[[],[],[]]\n",
    "odds=[]\n",
    "counter=0\n",
    "times=10\n",
    "for i in range(times):\n",
    "    for train_indx, test_indx in k_fold:\n",
    "        val_train_x, val_train_y =x_train[train_indx], y_train[train_indx]\n",
    "        val_test_x, val_test_y = x_train[test_indx], y_train[test_indx]\n",
    "    \n",
    "        est = [LogisticRegression(class_weight='balanced',penalty='l1', C=10, max_iter=500, fit_intercept=True),\n",
    "        #GaussianNB(),\n",
    "            AdaBoostClassifier(n_estimators=100),\n",
    "            RandomForestClassifier(n_estimators=500,class_weight='balanced'\\\n",
    "                   ,max_depth=6,bootstrap=False\\\n",
    "                   ,max_features=8,criterion='entropy')]\n",
    "    \n",
    "        for i in range(len(est)):\n",
    "            est[i].fit(val_train_x, val_train_y.ravel().T)\n",
    "            if i==0:\n",
    "                coefs= est[i].coef_\n",
    "            #print np.exp(coefs[:,[30,31,32,33]])\n",
    "            score = roc_auc_score(val_test_y, est[i].predict(val_test_x))\n",
    "            #print score\n",
    "            auc[i].append(score)\n",
    "\n",
    "means=[]\n",
    "errs=[]\n",
    "for score in auc:\n",
    "    means.append(np.mean(score)) #,np.mean(auc1),np.mean(auc2),np.mean(auc3)\n",
    "    errs.append(np.std(score))\n",
    "\n",
    "print means,errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63910802342008721, 0.64211392848481585, 0.65163449478404611] [0.042939514681446009, 0.029643126857972518, 0.034883694076084472]\n"
     ]
    }
   ],
   "source": [
    "means=[]\n",
    "errs=[]\n",
    "for score in auc:\n",
    "    means.append(np.mean(score)) #,np.mean(auc1),np.mean(auc2),np.mean(auc3)\n",
    "    errs.append(np.std(score))\n",
    "\n",
    "print means,errs\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Model performance\")\n",
    "#plt.bar(np.arange(4),height=1,color=\"r\", data=means,yerr=errs, align=\"center\")\n",
    "#plt.xticks(range(x_normed.shape[1]), indices)\n",
    "N = 3\n",
    "\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, means, width=0.6, color='#ffff00', yerr=errs)\n",
    "plt.axhline(y=0.5)\n",
    "plt.xlim(-0.1, 2.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimize random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3279, 36)\n",
      "[0.60639271856245924, 0.57433835478763196, 0.60006291854808802, 0.59471853904181926]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn import tree\n",
    "\n",
    "print x_normed.shape\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_normed, Y_arr, test_size=0.3)\n",
    "#print \"train/validation\",x_train.shape,y_train.shape\n",
    "#print \"test:\",x_test.shape,y_test.shape\n",
    "\n",
    "k_fold = StratifiedKFold(y_train.ravel(), n_folds=10)\n",
    "\n",
    "est = [rf(n_estimators=50,class_weight='balanced',max_depth=5,min_samples_split=10),\n",
    "            rf(class_weight='balanced',max_depth=5),\n",
    "            rf(n_estimators=200,class_weight='balanced',\\\n",
    "                                   max_depth=6),\n",
    "            rf(n_estimators=500,class_weight='balanced',max_depth=6,max_features='log2')]\n",
    "auc=[[] for i in est]\n",
    "odds=[]\n",
    "counter=0\n",
    "times=1\n",
    "\n",
    "for i in range(times):\n",
    "    for train_indx, test_indx in k_fold:\n",
    "        val_train_x, val_train_y =x_train[train_indx], y_train[train_indx]\n",
    "        val_test_x, val_test_y = x_train[test_indx], y_train[test_indx]\n",
    "        \n",
    "        for i in range(len(est)):\n",
    "            est[i].fit(val_train_x, val_train_y.ravel().T)\n",
    "            score = roc_auc_score(val_test_y, est[i].predict(val_test_x))\n",
    "            #print score\n",
    "            auc[i].append(score)\n",
    "\n",
    "means=[]\n",
    "errs=[]\n",
    "for score in auc:\n",
    "    means.append(np.mean(score)) #,np.mean(auc1),np.mean(auc2),np.mean(auc3)\n",
    "    errs.append(np.std(score))\n",
    "\n",
    "print means#,errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimize logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2295, 34)\n",
      "rank 1\n",
      "mean val score 0.647494553377 0.00802020014059\n",
      "paramters {'penalty': 'l1', 'C': 10, 'max_iter': 200, 'fit_intercept': True}\n",
      "rank 2\n",
      "mean val score 0.647058823529 0.0111876429783\n",
      "paramters {'penalty': 'l1', 'C': 1, 'max_iter': 200, 'fit_intercept': True}\n",
      "rank 3\n",
      "mean val score 0.647058823529 0.0084066864836\n",
      "paramters {'penalty': 'l2', 'C': 100, 'max_iter': 200, 'fit_intercept': True}\n",
      "rank 4\n",
      "mean val score 0.647058823529 0.0084066864836\n",
      "paramters {'penalty': 'l2', 'C': 100, 'max_iter': 100, 'fit_intercept': True}\n",
      "rank 5\n",
      "mean val score 0.647058823529 0.0084066864836\n",
      "paramters {'penalty': 'l1', 'C': 100, 'max_iter': 100, 'fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.grid_search import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from operator import itemgetter\n",
    "\n",
    "clf=lr(class_weight='balanced')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_normed, Y_arr, test_size=0.3)\n",
    "print x_train.shape\n",
    "def report(grid_scores,n_top=5):\n",
    "    top_scores=sorted(grid_scores,key=itemgetter(1),reverse=True)[:n_top]\n",
    "    for i,score in enumerate(top_scores):\n",
    "        print \"rank\",i+1\n",
    "        print \"mean val score\",score.mean_validation_score,np.std(score.cv_validation_scores)\n",
    "        print \"paramters\",score.parameters\n",
    "\n",
    "param_list={\"penalty\":['l1','l2'],\n",
    "            \"C\": [1,0.1,10,50,100],\n",
    "            \"max_iter\": [200,100],\n",
    "           \"fit_intercept\":[True,False]}\n",
    "n_iter_search=15\n",
    "random_search=RandomizedSearchCV(clf,param_distributions=param_list,\\\n",
    "                              n_iter=n_iter_search)\n",
    "random_search.fit(x_train,y_train)\n",
    "report(random_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search, random forest\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2295, 34)\n",
      "rank 1\n",
      "mean val score 0.653159041394 0.0114009135963\n",
      "paramters {'max_features': 8, 'bootstrap': False, 'criterion': 'entropy', 'max_depth': 8}\n",
      "rank 2\n",
      "mean val score 0.648801742919 0.00996619386773\n",
      "paramters {'max_features': 6, 'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4}\n",
      "rank 3\n",
      "mean val score 0.647930283224 0.00792497947808\n",
      "paramters {'max_features': 22, 'bootstrap': True, 'criterion': 'gini', 'max_depth': 4}\n",
      "rank 4\n",
      "mean val score 0.647494553377 0.00954103130377\n",
      "paramters {'max_features': 22, 'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4}\n",
      "rank 5\n",
      "mean val score 0.646623093682 0.01087248289\n",
      "paramters {'max_features': 10, 'bootstrap': False, 'criterion': 'entropy', 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.grid_search import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from operator import itemgetter\n",
    "clf=rf(n_estimators=200,class_weight='balanced')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_normed, Y_arr, test_size=0.3)\n",
    "print x_train.shape\n",
    "def report(grid_scores,n_top=5):\n",
    "    top_scores=sorted(grid_scores,key=itemgetter(1),reverse=True)[:n_top]\n",
    "    for i,score in enumerate(top_scores):\n",
    "        print \"rank\",i+1\n",
    "        print \"mean val score\",score.mean_validation_score,np.std(score.cv_validation_scores)\n",
    "        print \"paramters\",score.parameters\n",
    "\n",
    "param_list={\"max_depth\":[3,4,5,6,7,8],\n",
    "            \"max_features\": sp_randint(4, 34),\n",
    "           \"bootstrap\":[True,False],\n",
    "           \"criterion\":[\"gini\",\"entropy\"]}\n",
    "n_iter_search=15\n",
    "random_search=RandomizedSearchCV(clf,param_distributions=param_list,\\\n",
    "                              n_iter=n_iter_search)\n",
    "random_search.fit(x_train,y_train)\n",
    "report(random_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# test sample plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 34) (1606,)\n",
      "(689, 34) (689,)\n",
      "(984, 34) (984,)\n",
      "false pos  [ 0.         0.3253493  1.       ]\n",
      "0.635461995264\n",
      "0.635461995264\n",
      "0.628237861705\n",
      "0.628237861705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_normed, Y_arr, test_size=0.3)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n",
    "\n",
    "print x_train.shape,y_train.shape\n",
    "print x_val.shape,y_val.shape\n",
    "print x_test.shape,y_test.shape\n",
    "\n",
    "est = LogisticRegression(class_weight='balanced')\n",
    "est.fit(x_train, y_train.ravel())\n",
    "false_positive_rate, true_positive_rate, thresholds = \\\n",
    "    roc_curve(y_test, est.predict(x_test))\n",
    "print \"false pos \", false_positive_rate    \n",
    "print auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print roc_auc_score(y_test, est.predict(x_test))\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "label='Test AUC = %0.2f'% roc_auc,color='green')\n",
    "false_positive_rate, true_positive_rate, thresholds = \\\n",
    "    roc_curve(y_val, est.predict(x_val))\n",
    "\n",
    "print auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "print roc_auc_score(y_val, est.predict(x_val))\n",
    "\n",
    "#plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "#label='Validation AUC = %0.2f'% roc_auc)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "with open('model.output','wb') as myfile:\n",
    "    pickle.dump(est,myfile)\n",
    "legend = plt.legend(loc='upper center', shadow=True)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working logistic regression model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
